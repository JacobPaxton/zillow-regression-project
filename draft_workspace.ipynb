{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa93fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import acquire\n",
    "import prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6655c3e",
   "metadata": {},
   "source": [
    "\n",
    "# #1. Acquire the correct data subset from the 'zillow' dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88bc69",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91dc850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from env import host, username, password\n",
    "# def get_db_url(db_name, username=username, hostname=host, password=password):\n",
    "#     return f'mysql+pymysql://{username}:{password}@{hostname}/{db_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50be025",
   "metadata": {},
   "source": [
    "## Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a711dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = get_db_url(db_name='zillow')\n",
    "# query = \"\"\"\n",
    "#             SELECT parcelid as ID,\n",
    "#                     transactiondate as DateSold,\n",
    "#                     taxvaluedollarcnt as Worth,\n",
    "#                     taxamount as Taxes,\n",
    "#                     roomcnt as Rooms,\n",
    "#                     bathroomcnt as Baths,\n",
    "#                     bedroomcnt as Beds,\n",
    "#                     garagecarcnt as GarageCarCount,\n",
    "#                     numberofstories as Stories,\n",
    "#                     lotsizesquarefeet as LotSize,\n",
    "#                     garagetotalsqft as GarageSize,\n",
    "#                     calculatedfinishedsquarefeet as FinishedSize,\n",
    "#                     yearbuilt as YearBuilt,\n",
    "#                     fips as LocalityCode,\n",
    "#                     regionidcounty as County,\n",
    "#                     regionidzip as Zipcode,\n",
    "#                     propertycountylandusecode as UseCode\n",
    "#             FROM properties_2017\n",
    "#             JOIN predictions_2017 USING(parcelid)\n",
    "#             WHERE propertylandusetypeid = 261 AND \n",
    "#                   transactiondate BETWEEN '2017-05-01' AND '2017-08-31'\n",
    "#         \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d80f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql(query, url)\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6917aa78",
   "metadata": {},
   "source": [
    "## Store to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a874bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.isfile('zillow.csv'):\n",
    "#     df.to_csv('zillow.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d444e99",
   "metadata": {},
   "source": [
    "* **ACQUIRE.py**: \n",
    "    * Add get_db_url - *Done*\n",
    "    * Add acquire-store function - *Done*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef626ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DateSold</th>\n",
       "      <th>Worth</th>\n",
       "      <th>Taxes</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Baths</th>\n",
       "      <th>Beds</th>\n",
       "      <th>GarageCarCount</th>\n",
       "      <th>Stories</th>\n",
       "      <th>LotSize</th>\n",
       "      <th>GarageSize</th>\n",
       "      <th>FinishedSize</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>LocalityCode</th>\n",
       "      <th>County</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>UseCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11721753</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>205123.0</td>\n",
       "      <td>2627.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5672.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1316.0</td>\n",
       "      <td>1923.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>95997.0</td>\n",
       "      <td>0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11289917</td>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>136104.0</td>\n",
       "      <td>2319.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8284.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>97318.0</td>\n",
       "      <td>0101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11705026</td>\n",
       "      <td>2017-06-30</td>\n",
       "      <td>35606.0</td>\n",
       "      <td>543.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6707.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>3101.0</td>\n",
       "      <td>96018.0</td>\n",
       "      <td>0100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID    DateSold     Worth    Taxes  Rooms  Baths  Beds  \\\n",
       "0  11721753  2017-07-21  205123.0  2627.48    0.0    2.0   3.0   \n",
       "1  11289917  2017-06-23  136104.0  2319.90    0.0    2.0   3.0   \n",
       "2  11705026  2017-06-30   35606.0   543.69    0.0    1.0   2.0   \n",
       "\n",
       "   GarageCarCount  Stories  LotSize  GarageSize  FinishedSize  YearBuilt  \\\n",
       "0             NaN      NaN   5672.0         NaN        1316.0     1923.0   \n",
       "1             NaN      NaN   8284.0         NaN        1458.0     1970.0   \n",
       "2             NaN      NaN   6707.0         NaN        1421.0     1911.0   \n",
       "\n",
       "   LocalityCode  County  Zipcode UseCode  \n",
       "0        6037.0  3101.0  95997.0    0100  \n",
       "1        6037.0  3101.0  97318.0    0101  \n",
       "2        6037.0  3101.0  96018.0    0100  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.acquire_zillow()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9de5c68",
   "metadata": {},
   "source": [
    "* **Present**:\n",
    "    * Acquisition steps and data subsecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d98c3e",
   "metadata": {},
   "source": [
    "# #2. Create a distribution for residence locality (state, county) against tax rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca58247",
   "metadata": {},
   "source": [
    "* Notebook: Explore data for locality information\n",
    "    * **Deliverable**: List of states and counties where properties are located\n",
    "        * 6037: Los Angeles, CA\n",
    "        * 6059: Orange, CA\n",
    "        * 6111: Ventura, CA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d573c3",
   "metadata": {},
   "source": [
    "## Investigate locality information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "990a9e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[['County','LocalityCode']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c41e59",
   "metadata": {},
   "source": [
    "These three groups might be correct, let's investigate the Zipcode column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed117fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of unique zip codes, converted to five character str\n",
    "# zips = pd.DataFrame(df['Zipcode'].value_counts().keys().astype('int').astype('str').tolist())\n",
    "# Subsect zip codes to first three digits\n",
    "# zips[0] = zips[0].str[:3]\n",
    "# Show unique first-three-digits\n",
    "# zips.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f572f",
   "metadata": {},
   "source": [
    "- 961: Reno, NV (West)\n",
    "- 960: Redding, CA\n",
    "- 962: Armed Forces - Korea\n",
    "- 970: Portland, OR (Vicinity)\n",
    "- 963: Armed Forces - Japan\n",
    "- 969: Barrigda, Guam\n",
    "- 964: Armed Forces - Phillipines\n",
    "- 959: Marysville, CA\n",
    "- 965: Armed Forces - Pacific\n",
    "- 973: Salem, OR\n",
    "- 971: Portland, OR (West)\n",
    "- 399: Atlanta, GA (IRS)\n",
    "- 972: Portland, OR (Main)\n",
    "\n",
    "This doesn't seem quite right. The FIPS code might be the right one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47fff718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6037., 6059., 6111.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking aliased fips column\n",
    "df['LocalityCode'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e6f2bd",
   "metadata": {},
   "source": [
    "- 6037: Los Angeles, CA\n",
    "- 6059: Orange, CA\n",
    "- 6111: Ventura, CA\n",
    "\n",
    "This seems correct, these three are all counties in California. We're going with that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74930f",
   "metadata": {},
   "source": [
    "## Calculate tax rate for each property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc9ee095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Worth</th>\n",
       "      <th>Taxes</th>\n",
       "      <th>TaxRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>205123.0</td>\n",
       "      <td>2627.48</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136104.0</td>\n",
       "      <td>2319.90</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35606.0</td>\n",
       "      <td>543.69</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Worth    Taxes  TaxRate\n",
       "0  205123.0  2627.48     1.28\n",
       "1  136104.0  2319.90     1.70\n",
       "2   35606.0   543.69     1.53"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TaxRate'] = round((df['Taxes'] / df['Worth']) * 100, 2)\n",
    "df[['Worth','Taxes','TaxRate']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b92a39",
   "metadata": {},
   "source": [
    "## Create distribution of tax rates for each county\n",
    "* **Deliverable**: This distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "558f55cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(df, x='TaxRate', hue='LocalityCode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9206d794",
   "metadata": {},
   "source": [
    "That doesn't look right. Let's see what went wrong..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7f82ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.TaxRate.sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b581e",
   "metadata": {},
   "source": [
    "Ok, let's drop all values over 10% and see what happens..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5095160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(df[df.TaxRate < 10], x='TaxRate', hue='LocalityCode', palette='bright')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b05e89c",
   "metadata": {},
   "source": [
    "So it seems most values are between 1% and 2%, which checks. So let's see what value is poking out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50f91fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.TaxRate.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391af8db",
   "metadata": {},
   "source": [
    "The 2500-count value isn't appearing, weird. Let's zoom way in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1909aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = (df.TaxRate > 1.1) & (df.TaxRate < 1.5)\n",
    "# sns.histplot(df[mask], x='TaxRate', hue='LocalityCode', palette='bright')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217b321",
   "metadata": {},
   "source": [
    "So it seems two values were grouped into one bar. Let's widen the view a bit to capture the distribution without combining two tax rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c3cff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = (df.TaxRate > 0.9) & (df.TaxRate < 1.7)\n",
    "# sns.histplot(df[mask], x='TaxRate', hue='LocalityCode', palette='bright', kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b495e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_outliers(df, k, col_list):\n",
    "#     for col in col_list:\n",
    "#         q1, q3 = df[col].quantile([.25, .75])  # get quartiles\n",
    "#         iqr = q3 - q1   # calculate interquartile range\n",
    "#         upper_bound = q3 + k * iqr   # get upper bound\n",
    "#         lower_bound = q1 - k * iqr   # get lower bound\n",
    "#         # return dataframe without outliers\n",
    "#         df = df[(df[col] > lower_bound) & (df[col] < upper_bound)]\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4e29399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new = prep.remove_outliers(df, 1.5, ['TaxRate','Worth','Taxes'])\n",
    "# sns.histplot(new, x='TaxRate', hue='LocalityCode', palette='bright', kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609371a0",
   "metadata": {},
   "source": [
    "Cool. So, clean up this distribution and put it in the presentation. Some things you should note:\n",
    "- Each locality's highest rate\n",
    "- General shape of distributions\n",
    "- Any odd phenomenon, like the seemingly-random peaks through the skew\n",
    "    * This is likely two values grouped into one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a4f68e",
   "metadata": {},
   "source": [
    "* **Present**: \n",
    "    * All localities for dataset's residences\n",
    "    * Each locality's tax rate range\n",
    "    * Each peak in the tax rate distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53869518",
   "metadata": {},
   "source": [
    "# #3. Conduct hypothesis testing and check univariate distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b6bfd",
   "metadata": {},
   "source": [
    "### Univariate Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2c4abe",
   "metadata": {},
   "source": [
    "* Notebook: Initial exploration\n",
    "    * Use square-footage, bedroom-count, bathroom-count, and tax-value for initial exploration\n",
    "    * *After MVP*: Run initial exploration on new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7eadc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0012c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial = df[['Worth','FinishedSize','Beds','Baths']]\n",
    "# print(initial.info())\n",
    "# initial = initial.dropna()\n",
    "# initial = initial.drop_duplicates()\n",
    "# initial.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00396310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def initial_plots(df):\n",
    "#     for col in df.columns:\n",
    "#         # Raw plots\n",
    "#         sns.histplot(df, x=col)\n",
    "#         plt.title(col)\n",
    "#         plt.show()\n",
    "        \n",
    "#         # Interquartile Rule\n",
    "#         q1, q3 = df[col].quantile([.25, .75])  # get quartiles\n",
    "#         k = 1.5\n",
    "#         iqr = q3 - q1   # calculate interquartile range\n",
    "#         upper_bound = q3 + k * iqr   # get upper bound\n",
    "#         lower_bound = q1 - k * iqr   # get lower bound\n",
    "#         temp = df[(df[col] > lower_bound) & (df[col] < upper_bound)]\n",
    "#         sns.histplot(temp, x=col)\n",
    "#         plt.title(col + '_no_outliers')\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16935f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Worth'].dtype == 'float64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ed26309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep.initial_plots(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a10df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep.initial_plots(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9692462",
   "metadata": {},
   "source": [
    "### Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9703ecc7",
   "metadata": {},
   "source": [
    "* Notebook: Hypothesis testing\n",
    "    * Create initial hypotheses for MVP features, push to readme\n",
    "    * Run statistical tests\n",
    "        * At least two statistical tests along with visualizations documenting hypotheses and takeaways\n",
    "    * Convey results to readme and Jupyter notebook\n",
    "    * *After MVP*: Create hypotheses for new features \n",
    "    * *After MVP*: Push new features through hypothesis testing to check viability\n",
    "    * *After MVP*: Convey results to readme and Jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3192b60e",
   "metadata": {},
   "source": [
    "**Initial Hypotheses** (two for MVP):\n",
    "- There is a linear relationship between a home's value and the number of bedrooms it has.\n",
    "- The value of a home with two bedrooms is not statistically different from a home with two bathrooms.\n",
    "\n",
    "**Confidence Interval = 95%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c405c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def significant(alpha, p):\n",
    "    if p < alpha:\n",
    "        print(\"Reject the null hypothesis\")\n",
    "    else:\n",
    "        print(\"Accept the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9848f95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "# Spearman test to determine correlation between Worth and Beds\n",
    "alpha = .05\n",
    "corr, p = stats.spearmanr(df.dropna().Worth, df.dropna().Beds)\n",
    "significant(alpha, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d2f5670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "# Mannwhitney test to determine statistical difference between \n",
    "# Worth of homes with 2 Beds and Worth of homes with 2 Baths\n",
    "t, p = stats.mannwhitneyu(df[df.Beds == 2].dropna().Worth, df[df.Baths == 2].dropna().Worth) \n",
    "if p > alpha: # Note: hypothesis is that there *isn't* a statistical difference\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Accept the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d0baed",
   "metadata": {},
   "source": [
    "* **PREP.py**: \n",
    "    * Add initial-plots function to loop through and plot features - *Done*\n",
    "* **Present**: \n",
    "    * First four distributions\n",
    "    * *After MVP*: Any additional distributions included/excluded\n",
    "    * Initial hypotheses\n",
    "    * Statistical tests\n",
    "    * Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d26e9ec",
   "metadata": {},
   "source": [
    "# #4. Prepare using Minimum-Viable-Product (MVP) specification restriction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d7391",
   "metadata": {},
   "source": [
    "### 1. Drop all columns except square-footage, bedroom-count, bathroom-count, tax-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5343f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[['Worth','FinishedSize','Beds','Baths']]\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e050f266",
   "metadata": {},
   "source": [
    "### 2. Drop all nulls and duplicates in above columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4f86dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Before:\", df.shape)\n",
    "# df = df.dropna().drop_duplicates()\n",
    "# print(\"After:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "255d99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Before:\", df.shape)\n",
    "# df = df\n",
    "# print(\"After:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ecaf4",
   "metadata": {},
   "source": [
    "### 3. Check for outliers using box-and-whisker plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9b9f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df.columns:\n",
    "#     sns.boxplot(data=df[col])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4c892",
   "metadata": {},
   "source": [
    "### 4. Eliminate outliers if needed using Inter-Quartile Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b33d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = remove_outliers(df, k=1.5, col_list=['Worth','FinishedSize','Beds','Baths'])\n",
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880b8659",
   "metadata": {},
   "source": [
    "### 5. Rename columns to something more readable\n",
    "- Accomplished in SQL query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b004cc9",
   "metadata": {},
   "source": [
    "### 6. Split data into train, validate, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61aaea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_validate, test = train_test_split(df, test_size=0.2, random_state=123)\n",
    "# train, validate = train_test_split(train_validate, test_size=0.25, random_state=123)\n",
    "# train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3779aed",
   "metadata": {},
   "source": [
    "### 7. Isolate target variable 'tax-value' into y_train from X_train\n",
    "Do the same for X_validate and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22d4c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = train.drop(columns='Worth'), train.Worth\n",
    "# X_validate, y_validate = validate.drop(columns='Worth'), validate.Worth\n",
    "# X_test, y_test = test.drop(columns='Worth'), test.Worth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0bf9b5",
   "metadata": {},
   "source": [
    "### 8. Scale data\n",
    "* Create and fit scaler using X_train\n",
    "* Create X_train_exp using scaler transform of X_train while retaining original values\n",
    "* Scale X_train, drop unscaled columns\n",
    "* Scale X_validate, drop unscaled columns\n",
    "* Scale X_test, drop unscaled columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1e2f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d64fb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_exp = X_train.copy()\n",
    "# col_list = []\n",
    "# for col in X_train.columns:\n",
    "#     col_list.append(col + \"_scaled\")\n",
    "# X_train_exp[col_list] = scaler.transform(X_train)\n",
    "# X_train_exp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2432d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = scaler.transform(X_train)\n",
    "# X_validate = scaler.transform(X_validate)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78102de0",
   "metadata": {},
   "source": [
    "* *After MVP*: Run through above steps as needed with any additional features\n",
    "* **PREP.py**: \n",
    "    * Add plot-data function to make various plots for a dataframe when called - *Done*\n",
    "    * Add clean-data function to limit dataset features, drop nulls, eliminate outliers, rename columns - *Done*\n",
    "        * *After MPV*: Revise clean-data with new features\n",
    "    * Add split-data function for train/validate/test *and* target isolation - *Done*\n",
    "    * Add scale-data function - *Done*\n",
    "    * Add wrangle-data function to run acquire-store, clean-data, split-data, and scale-data functions, then return all dataframes - *Done*\n",
    "* **Present**:\n",
    "    * Overview of wrangling, mentioning feature limitation to MVP, additional features, nulls, outliers, feature renaming, split, target isolation, scaler creation, scaler application, returned dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe9553c",
   "metadata": {},
   "source": [
    "## Check to see if prep.py is working as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b26a1152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FinishedSize</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Baths</th>\n",
       "      <th>FinishedSize_scaled</th>\n",
       "      <th>Beds_scaled</th>\n",
       "      <th>Baths_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12185</th>\n",
       "      <td>2890.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.897476</td>\n",
       "      <td>2.254989</td>\n",
       "      <td>2.574043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17845</th>\n",
       "      <td>1352.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.598498</td>\n",
       "      <td>-0.278078</td>\n",
       "      <td>-0.167565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28109</th>\n",
       "      <td>1516.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.332348</td>\n",
       "      <td>0.988456</td>\n",
       "      <td>-0.167565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FinishedSize  Beds  Baths  FinishedSize_scaled  Beds_scaled  \\\n",
       "12185        2890.0   5.0    4.0             1.897476     2.254989   \n",
       "17845        1352.0   3.0    2.0            -0.598498    -0.278078   \n",
       "28109        1516.0   4.0    2.0            -0.332348     0.988456   \n",
       "\n",
       "       Baths_scaled  \n",
       "12185      2.574043  \n",
       "17845     -0.167565  \n",
       "28109     -0.167565  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, X_train_exp, X_train, y_train, X_validate, y_validate, X_test, y_test = prep.wrangle_zillow_MVP()\n",
    "X_train_exp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d846af1c",
   "metadata": {},
   "source": [
    "# #5. Create models for MVP restriction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013be7ee",
   "metadata": {},
   "source": [
    "### 1. Cast y_train and y_validate as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6cba42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14848, 1), (4950, 1))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "y_validate = pd.DataFrame(y_validate)\n",
    "y_train.shape, y_validate.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db28ee",
   "metadata": {},
   "source": [
    "### 2. Create model-performance function\n",
    "* Takes in actuals_series, predictions_series, 'model_name', df_to_append_to\n",
    "* Calculates RMSE\n",
    "* Calculates r^2 score\n",
    "* Appends dataframe with new row for model_name, RMSE_validate, r^2_score\n",
    "* Returns dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f46e53e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(train_actuals, val_actuals, train_preds, val_preds, model_name, running_df):\n",
    "    rmse_train = mean_squared_error(train_actuals, train_preds) ** 0.5\n",
    "    rmse_validate = mean_squared_error(val_actuals, val_preds) ** 0.5\n",
    "    r2_train = r2_score(train_actuals, train_preds)\n",
    "    r2_validate = r2_score(val_actuals, val_preds)\n",
    "    running_df = running_df.append({'Model':model_name, \n",
    "                                   'Train_RMSE': rmse_train,\n",
    "                                   'Validate_RMSE': rmse_validate,\n",
    "                                   'Train_r2': r2_train,\n",
    "                                   'Validate_r2': r2_validate}, ignore_index=True)\n",
    "    return running_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7528299",
   "metadata": {},
   "source": [
    "### 3. Create plot-residuals function - WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed7e7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_residuals(df):\n",
    "#     sns.relplot(x = 'total_bill', y = 'residual', data = df)\n",
    "#     plt.axhline(0, ls = ':')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0b90b1",
   "metadata": {},
   "source": [
    "### 4. Create baseline model\n",
    "* Calculate mean and median of target (tax-value)\n",
    "* Assign mean and median to columns in y_train and y_validate\n",
    "* Calculate RMSE for both train and validate\n",
    "    * mean_squared_error(actuals, baseline) ** 0.5\n",
    "* Keep the lower-error baseline (of mean and median)\n",
    "* Call plot-residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39559b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Worth</th>\n",
       "      <th>mean_bl</th>\n",
       "      <th>median_bl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12185</th>\n",
       "      <td>683726.0</td>\n",
       "      <td>388435.613618</td>\n",
       "      <td>346509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17845</th>\n",
       "      <td>418993.0</td>\n",
       "      <td>388435.613618</td>\n",
       "      <td>346509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28109</th>\n",
       "      <td>348477.0</td>\n",
       "      <td>388435.613618</td>\n",
       "      <td>346509.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Worth        mean_bl  median_bl\n",
       "12185  683726.0  388435.613618   346509.0\n",
       "17845  418993.0  388435.613618   346509.0\n",
       "28109  348477.0  388435.613618   346509.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['mean_bl'] = y_train['Worth'].mean()\n",
    "y_train['median_bl'] = y_train['Worth'].median()\n",
    "y_validate['mean_bl'] = y_validate['Worth'].mean()\n",
    "y_validate['median_bl'] = y_validate['Worth'].median()\n",
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc9db337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Validate_RMSE</th>\n",
       "      <th>Train_r2</th>\n",
       "      <th>Validate_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, Train_RMSE, Validate_RMSE, Train_r2, Validate_r2]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_df = pd.DataFrame(columns=['Model','Train_RMSE','Validate_RMSE','Train_r2','Validate_r2'])\n",
    "running_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6b3b29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Validate_RMSE</th>\n",
       "      <th>Train_r2</th>\n",
       "      <th>Validate_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mean_baseline</td>\n",
       "      <td>260807.509266</td>\n",
       "      <td>265580.600849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>median_baseline</td>\n",
       "      <td>264156.010378</td>\n",
       "      <td>268905.009083</td>\n",
       "      <td>-0.025843</td>\n",
       "      <td>-0.025192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model     Train_RMSE  Validate_RMSE  Train_r2  Validate_r2\n",
       "0    mean_baseline  260807.509266  265580.600849  0.000000     0.000000\n",
       "1  median_baseline  264156.010378  268905.009083 -0.025843    -0.025192"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_df = model_performance(y_train.Worth, y_validate.Worth, y_train.mean_bl, y_validate.mean_bl, 'mean_baseline', running_df)\n",
    "running_df = model_performance(y_train.Worth, y_validate.Worth, y_train.median_bl, y_validate.median_bl, 'median_baseline', running_df)\n",
    "running_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d032ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fbeabe6",
   "metadata": {},
   "source": [
    "### 5. Create models for different regression algorithms\n",
    "* Loop through one algorithm's hyperparameters, save to list\n",
    "* Loop through next algorithm, and next... using same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e78b36",
   "metadata": {},
   "source": [
    "### 6. Loop lists of models through model-performance function\n",
    "* Extend the 'model_name' to include hyperparameter\n",
    "* Add to same dataframe for easy column-wise analysis\n",
    "* Call plot-residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e9abb6",
   "metadata": {},
   "source": [
    "### 7. \"Choose\" best-performing model\n",
    "* Plot y by yhat\n",
    "* *After MVP*: Add features, use k-best or RFE to determine which features to include\n",
    "* *After MVP*: Loop model-performance using new feature set and suitable names\n",
    "* *After MVP*: \"Choose\" best-performing model\n",
    "* **Present**: \n",
    "    * model-performance function\n",
    "    * baseline performance\n",
    "    * MVP model performance\n",
    "    * After-MVP model performance\n",
    "    * model selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c385eb5",
   "metadata": {},
   "source": [
    "# #6. Revisit Step #3, #4, and #5 with more features than the MVP restriction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9630c6",
   "metadata": {},
   "source": [
    "* Complete these steps:\n",
    "    * Run at least 1 t-test and 1 correlation test (but as many as you need!)\n",
    "    * Visualize all combinations of variables in some way(s).\n",
    "    * What independent variables are correlated with the dependent?\n",
    "    * Which independent variables are correlated with other independent variables?\n",
    "* Run all *After MVP* steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70616d1",
   "metadata": {},
   "source": [
    "# #7. Push work and findings to a slide deck\n",
    "- Practice/script the presentation\n",
    "- Present!\n",
    "\n",
    "# Notes to self\n",
    "- \"You will want to make sure you are using the best fields to represent square feet of home, number of bedrooms, and number of bathrooms. \"Best\" meaning the most accurate and available information. Here you will need to do some data investigation in the database and use your domain expertise to make some judgement calls.\"\n",
    "- \"Brainstorming ideas and form hypotheses related to how variables might impact or relate to each other, both within independent variables and between the independent variables and dependent variable.\"\n",
    "- \"Document any ideas for new features you may have while first looking at the existing variables and the project goals ahead of you.\"\n",
    "- \"Add a data dictionary in your notebook at this point that defines all the fields used in your model and your analysis and answers the question, \"Why did you use the fields you used?\". e.g. \"Why did you use bedroom_field1 over bedroom_field2?\", not, \"Why did you use number of bedrooms?\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6947c2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
